\magnification=1000
\hsize=36truepc \vsize=55truepc 
\parindent=18truept \parskip=0pt 
\baselineskip=20pt plus 2pt minus 1pt \lineskiplimit=2pt
\lineskip=2pt plus 2pt \tolerance=800

\font\rmeight=cmr8  \def\rmVIII{\rmeight \baselineskip=10pt
 plus 2pt minus 1pt \lineskiplimit=2pt \lineskip=2pt plus 2pt
 \def\sstrut{\vrule height 7.5pt depth 2.5pt width 0pt}\parskip=0pt}
\font\caps=cmcsc10 \font\slIX=cmsl9
\font\rmIX=cmr9 \font\bfIX=cmbx9 \font\rmXII=cmr12 \font\bfXII=cmbx12
\font\bfXIV=cmbx12 at 14pt
\font\rmXIV=cmr12 at 14pt \font\rmXVIII=cmr17 at 18pt
\font\bfXVIII=cmbx18
\font\bfVIII=cmbx8 \font\slVIII=cmsl8

\input epsf % For Postscript figures: {\epsfxsize=  \epsffile{}}

\def\section#1#2{\par\vskip 17pt\leftline{\bf#1.\hskip 14truept#2}
\nobreak\smallskip\noindent\ignorespaces}
\let\xpar=\par
\def\smallfn#1#2{{\def\strut{\sstrut\xpar\kern2pt}\rmVIII\footnote
 {#1}{#2}}}
\def\R{\mathop{\rm I}\!\!\mathop{\rm R}\nolimits}
\nobreak
\def\caption#1#2{\parindent=8pt
  \narrower\narrower\noindent\hlvb Figure #1. #2\par}
\def\tabcaption#1#2{\parindent=20pt
  \narrower\narrower\noindent\hlvb Table #1. #2\par}
\def\heading#1#2{\par\vskip-\lastskip\bigskip
 \leftline{\bfXII #1 #2}\nobreak\medskip}
\def\sheading#1#2{\par\vskip-\lastskip\bigskip
 \leftline{\bfXI #1 #2}\nobreak\medskip}
\def\ssheading#1#2{\par\vskip-\lastskip\bigskip
  \noindent{\bf #1 #2. }\ignorespaces}
\def\lheading#1#2{\par\vskip-\lastskip\bigskip % > 1 line heading
  {\bfXII\setbox11=\hbox{#1 }\hangindent=\wd11 \hangafter=1
  \noindent #1 #2\par}\nobreak\medskip}
\def\lsheading#1#2{\par\vskip-\lastskip\bigskip % > 1 line subheading
  {\bfXI\setbox11=\hbox{#1 }\hangindent=\wd11 \hangafter=1
  \noindent #1 #2\par}\nobreak\medskip}
\def\bull{\item{$\bullet$}} \let\xpar=\par
\def\smallfn#1#2{{\def\strut{\xpar\kern2pt}\rmVIII \footnote {#1}{#2}}}
%
% Set up reference labels. Usage: \rn\Name in prologue and \Name\ in
%				  text instead of [1].
\newcount\refNUM \refNUM=0
\def\rn#1{\advance\refNUM by 1
	\edef#1{\hbox{[\number\refNUM]}}}

\rn \AD
\rn \ASZ
\rn \ASZI
\rn \C
\rn \D
\rn \DPAM
\rn \DT
\rn \DWC
\rn \E
\rn \GF
\rn \GSG
\rn \HWRSVJBT
\rn \JPS
\rn \KWT
\rn \MM
\rn \RKW
\rn \TZWBIB
\rn \VL
\rn \WCSF
\rn \WIHM

\headline={\hfil}
\footline={\hfil}

\centerline{\bfXIV Multiobjective optimization Using an Adaptive Weighting Scheme}
\vskip 1.2pc
\centerline{\rmXII Shubhangi Deshpande{$^a$}, Layne T. Watson{$^{a,b}$
}, Robert A. Canfield$^c$}
\smallskip
\centerline{\rmVIII $^a$Department of Computer Science, Virginia Polytechnic 
Institute \& State University, Blacksburg, VA}
\centerline{\rmVIII $^b$Department of Mathematics, Virginia Polytechnic 
Institute \& State University, Blacksburg, VA}
\centerline{\rmVIII $^c$Department of Aerospace \& Ocean Engineering, Virginia 
Polytechnic Institute \& State University, Blacksburg, VA}
\bigskip

\noindent{\bf Abstract}
\smallskip
\noindent 
\bigskip\noindent{\it Keywords:} multiobjective optimization; Pareto 
optimality; direct search method; DIRECT; MADS; surrogates; triangulation.
\smallskip
\hrule
\smallskip
%
% equation numbers at left, numbered within section.  Subsection numbers
% of form  a.b.c  .  Theorems, definitions, figures in SIAM journal format.
%

\section{1}{Introduction}% begin text without a blank line in between
Multiobjective optimization problems (MOP) arise in practically every domain 
of science and engineering where optimal decisions need to be taken in 
the presence of two or more conflicting objectives. A decision maker has to 
take into account different criteria that need to be satisfied
simultaneously.

Let $\R^n$ denote real $m$-dimensional Euclidean space. For vectors $x^{(1)}$, 
$x^{(2)}$ $\in \R^n$ write $x^{(1)} < x^{(2)}$ $(x^{(1)}\le x^{(2)})$ if 
$\forall i$, $x^{(1)}_i<x^{(2)}_i (x^{(1)}_i\le x^{(2)}_i)$, $i=0$, $\ldots$, 
$n$. Let $l$, $u \in \R^n$ with $l < u$ and $B = \{ x \in \R^n \mid l\le x\le 
u\}$. Given $m$ conflicting objective functions $f_i: B \to \R$, $i=1,\ldots,m$, 
the multiobjective optimization problem is to simultaneously minimize all the 
$f_i$ over $B$.

For a nontrivial multiobjective optimization problem with $m$ conflicting 
objectives no single solution can optimize all $m$ objectives simultaneously. 
Hence, a new notion of optimality, known as Pareto optimality (and the set of 
optimal solutions as the Pareto front), is generally used in the context of
multiobjective optimization problems. Pareto optimality generally defined using
a dominance relation is as follows: Given two decision vectors $x^{(1)}$ and
$x^{(2)}$, $x^{(1)}$ is said to dominate $x^{(2)}$ if and only if $x^{(1)}$ is
no worse than $x^{(2)}$ in all objectives, and $x^{(1)}$ is strictly better
than $x^{(2)}$ in at least one objective. This is generally denoted as
$x^{(1)}\prec x^{(2)}$.

A solution $x^*$ is a globally Pareto optimal solution if and only if there 
does not exist any $x$ in the design space such that $x\prec x^*$. 

A solution $x^*$ is a locally Pareto optimal solution if and only if there 
does not exist any $x$ in $\epsilon$-neighborhood $\bigl\{ x \mid\|x-x^*\| 
\le\epsilon \bigr\}\cap B$ of $x^*$ that dominates $x^*$, for some $\epsilon > 0$.  

The goal of a MOP is to find all the Pareto optimal solutions among all the
conflicting objectives. In general, finding infinitely many solutions on a
Pareto front is impossible, and finding even a large discrete subset is hard
when the structure and/or the analytical form of the underlying objective
function is not known or is very complex (e.g., blackbox simulation
optimization). An approximation to the true Pareto front is obtained as an
alternative in such situations. The most common approach is to approximate the
Pareto front by a discrete set of solutions. The other difficulty is the
efficient generation of well distributed Pareto optimal solutions. In real
design problems a decision maker might be able to consider only a subset of the
available solution set. In this context, having a good representation of the
entire Pareto front is a crucial requirement in order to make an informed
decision. Efficiency (in terms of the total number of true function
evaluations) of a multiobjective optimization algorithm is a key factor in
practical multidisciplinary design optimization problems where a design cycle
involves time consuming and expensive computations at each discipline. For
example, in a conceptual aircraft design process several different disciplines
influence each other resulting in several interdisciplinary iterations 
to reach a feasible optimal design. The task becomes even more complicated 
when the objective functions are evaluated using expensive blackbox 
simulations where analytical form of the objective functions is not 
available or is very complex.  

The aim of this paper is to propose a new method that provides a well 
distributed representation of the Pareto front for multiobjective blackbox 
optimization with a minimal number of true function evaluations. 
The general idea is to systematically move towards the Pareto front at the end
of every iteration by adaptively filling the gaps between the nondominated
solutions obtained so far. The biobjective optimization method proposed in
\DWC\ by the authors of this paper was based on the scalarization scheme of Ryu
et al. \RKW. However, the same adaptive weighting scheme does not work for
multiobjective problems due to the lack of certain properties in higher
dimensions. The algorithm presented in this paper proposes an alternative
approach for generalizing the adaptive weighting scheme of Ryu et al. \RKW\ to
the problems with more than two objectives. The algorithm employs a hybrid
approach using two derivative free direct search techniques --- a deterministic
global search algorithm, DIRECT \JPS\ for global exploration of the design
space and a local direct search method, MADS (mesh adaptive direct search) \AD\
to exploit the design space by fine tuning the potentially optimal regions
returned by DIRECT and to speed up the convergence.  The true function
evaluations are replaced by cheaper surrogates to the objective
functions in order to minimize the expensive simulation runs. The proposed 
method uses the global search algorithm DIRECT as a sampling
method instead of using traditional random sampling (e.g., Latin hypercube 
sampling) or factorial designs that  proved to be promising in higher dimensional 
design spaces (see Section 4.1.4). Results show that the proposed method provides 
well distributed Pareto optimal fronts for diverse types of problems. 
Another contribution is the use of a precise mathematical measure, known 
as star discrepancy, as a measure for computing the distribution of the 
Pareto optimal solutions. A biobjective version presented in \DWC\ has been 
generalized in present work for the problems with more than two objectives. A
detailed description is provided in the Section 4.  

The organization of this paper is as follows. Section 2 gives an overview  
of the existing multiobjective optimization approaches in general and the 
previous work by the authors on biobjective optimization problems in particular, 
and also provides a background on surrogates and hybrid optimization approches 
in the context of multiobjective optimization. Section 3 describes the proposed  
alternative scalarization scheme and presents the multiobjective optimization 
algorithm. Numerical evaluation on a set of test problems from the literature 
is presented and results are discussed in the Section 4. Section 5 offers 
concluding remarks.
 
\section{2}{Background} 
Many different methods have been suggested in the literature for solving 
multiobjective optimization problems. The solution approaches can be divided 
into two broad categories --- evolutionary approaches and scalarization or 
aggregation approaches. Applying a Pareto based ranking scheme using 
genetic algorithms has become very common and popular in most of the 
evolutionary approaches (e.g., \DPAM,), although some schemes based on 
particle swarm intelligence and simulated annealing are significant too. 
An evolutionary approach yields a set of Pareto solutions at the end of each 
iteration, however, requires a very large number of true function evaluations 
and does not guarantee optimality in general. Aggregate or scalarization 
approaches \E are considered to be classical methods for solving 
multiobjective optimization problems. A general idea is to combine all 
objective functions to convert a multiobjective optimization problem into a 
single objective optimization problem. Thus at the end of each iteration it 
yields a single solution by solving a single objective optimization problem.
The most commonly used scalarization approach is the weighted sum method 
where the multiobjective optimization problem is converted to a single 
optimization problem using a predefined weight vector. A major drawback 
of the weighted sum method is that if the Pareto front has a nonconvex 
region then the method fails to produce any points in that region. Also uniformly
distributed weights may not produce uniformly distributed optimal points on the 
front. To alleviate this problem an adaptive weighting scheme was suggested 
by Ryu et al. in their biobjective optimization algorithm PAWS \RKW. PAWS 
has an efficient weighting scheme, however the central composite designs based 
sampling strategy used in PAWS is impractical in higher dimensional search 
domains. Deshpande et al. \DWC\ proposed an algorithm for biobjective 
optimization that employs the adaptive weighting scheme of PAWS, but 
tries to overcome the limitation of PAWS with a novel sampling strategy 
and a global search method. The ordering property exploited in the algorithms 
of \RKW\ and \DWC\ does not work in higher dimensions. Hence, an alternative
strategy is proposed in this paper that works for problems with any number of
objectives. 

Other methods like normal boundary intersection[], successive Pareto 
optimization[], directed search domain[] solve multiobjective optimization 
problems by constructing several aggregate objective functions. A scalarization
method called BiMADS \ASZ\ solves a biobjective optimization problem through a
series of single objective formulations using the direct search method MADS,
and attempts to obtain a uniform coverage of the Pareto front, even in the case
when the Pareto front is nonconvex or disjoint. Results produced using BiMADS
are dependent on the specific implementation of the algorithm (e.g., Latin
hypercube sampling used for the very first run in NOMAD 3.5.1 may not produce
consistent results always). BiMADS also exploits the ordering property
available in two dimensional case, and hence is not applicable in problems with
more than two objectives. Audet et al. suggested an alternate formulation in
\MM\ to generalize their scheme for the problems with more than two
objectives. 

Several real world scientific and engineering applications require analysis of 
spatially distributed data from expensive experiments or complex computer 
simulations that can take hours to run even on a fast workstation. This makes 
it difficult to explore and produce all design combinations in large high 
dimensional design spaces. Identifying the regions that contain good designs in 
such data-scarce domains by keeping the number of simulation runs to 
a minimum is a nontrivial problem. The proposed algorithm employs 
a systematic way to enrich an incomplete database by adaptively 
filling the gaps between the nondominated points obtained from available data. 
The work in this paper deals with multiobjective optimization problems for 
such black box simulations where the structure of the objective functions is 
not known or is very complex. To tackle the problem of expensive simulation 
runs and to reduce the number of true function evaluations, computationally 
cheap(er) approximations (known as surrogates) of the underlying complex 
functions are used in the proposed work. Statistical sampling is a crucial 
part of a surrogate building process which becomes nontrivial in higher 
dimensional search domains. The novel idea proposed in the previous work by the
authors in \DWC\ of using the optimization algorithm DIRECT as a sampling 
strategy is employed in the current work as well. 

Hybrid optimization is a popular approach in the optimization community where 
several different optimization techniques are combined to improve robustness 
and blend distinct strengths of different approaches \GF. This same 
notion has been extended to multiobjective optimization problems in \WIHM. 
The Pareto approximation method of this paper is a hybrid approach using two 
direct search methods, DIRECT (to explore the design space globally) and 
MADS (to fine tune the potentially optimal regions returned by DIRECT), to 
balance between global and local searches and to improve the convergence rate.

\section{3}{The Multiobjective Optimization Algorithm}
This paper proposes a new method for multiobjective optimization of possibly 
nonsmooth functions. The ordering property (that the objective functions can be
ordered in two dimensions) available in two dimensions is exploited in the
biobjective case to find the most isolated point from a set of nondominated
solutions at each iteration. However, due to the lack of ordering in higher
dimensions, the same strategy cannot be implemented in the multiobjective case.
Hence, an alternative using a concept, borrowed from computational geometry,
known as triangulation is proposed in this paper.  Section 3.1 proposes this
alternate approach, and the general scheme of the multiobjective optimization
algorithm is presented in the Section 3.2.

\section{3.1}{An alternative using Delaunay triangulation}
In the biobjective optimization case, a point with the largest Euclidean 
distance with its neighbors is selected as the most isolated point provided 
that the data points are ordered in either of the two objectives. However, 
this notion of ordering does not exist in higher dimensions. Hence, an alternative 
is proposed for identifying the most isolated point in a high dimesnional 
objective space. This is achieved by using a concept from computational geometry, 
known as triangulation. Triangulation of a discrete set of points is a
subdivision of the convex hull of the points into simplices (e.g. a set of 
triangles in 2D). A frequently used and studied point set triangulation is the
Delaunay triangulation. A Delaunay triangulation of a point set is a
triangulation of the point set with the property that no point in the point set
falls in the interior of the circumcircle of any triangle in the triangulation.
Once the triangulation is constructed for the current nondominated point set,
the average distance of each vertex from its neighbors (given two vertices
$v_1$ and $v_2$, $v_1$ is a neighbor of $v_2$ [and $v_2$ a neighbor of $v_1$]
if there is a common edge between $v_1$ and $v_2$ in the given triangulation)
is computed, and the vertex with the largest average distance from its
neighbors is then considered as the most isolated point for that iteration. The
precise mathematical formulation of this process is presented in the next
subsection. 

\section{3.2}{The optimization algorithm} 
As a preprocessing step, a global search is performed using DIRECT to explore
the design space in unsampled regions of a database (if the database is empty,
the global exploration step becomes the data generation step). DIRECT being an
optimization algorithm, the design space exploration is conducted in an
intelligent manner by focusing the global search in potentially optimal regions
only. For this initialization step, $p+1$ single objective formulations using
$p+1$ weight vectors are obtained --- $p$ of which correspond to the individual
optima of the $p$ objective functions and one more with the equal preference to
all the objectives ($w^i=1/p$, $i=1$, $\ldots$, $p$, $\sum_{i=1}^{p}w_i=1$). 
Due to peculiar sampling strategy of DIRECT, it never samples the boundary 
points of a design space or takes a large number of iterations to reach 
reasonably close to the boundary. On account of this behaviour of DIRECT, 
the potentially optimal regions returned by DIRECT are fine tuned using MADS. 
Using the data collected in DIRECT's global search a surrogate is built over 
the entire design space to find individual optimum for each objective function 
using MADS. The candidate solutions are evaluated and stored in the database.

The preprocessing step is a crucial part of the proposed algorithm. It helps 
in eliminating a subset of local optima and accelerates the process of moving 
to the Pareto front. However, it does not eliminate all the local optima (as 
the preprocessing is done using a fixed set of weights), and hence the 
algorithm may not find a global Pareto front always.    

A set $X^0$ of nondominated points (with respect to all database points) is
obtained at the end of the preprocessing step that serves as an input or
starting point for the iterative procedure of the algorithm that follows. 
Each iteration of the algorithm consists of three steps: finding the most 
isolated point from the current nondominated point set, constructing surrogates 
for the objective functions with the isolated point determined in Step 1 as 
the center, and solving several single objective optimization problems to 
produce candidate Pareto solutions. At the beginning of the iterative process, 
a  trust region radius $\Delta^0$, the trust region contraction parameter 
$\rho$, and the tolerance value $\tau$ for the trust region radius are 
initialized to user defined values. \smallskip

\noindent{\bf Step 1: Isolated point determination}\smallskip

\noindent Let $X^{(k)} = \bigl\{x^{(k,1)}$,$\ldots$,$x^{(k,J_k)}\bigr\}$ be the 
set of nondominated points at the start of the iteration $k$ and 
$P^{(k)} = \bigl\{F(x^{(k,1)})$, $F(x^{(k,2)})$,$\ldots$,$F(x^{(k,J_k)})\bigr
\}$ be the corresponding objective space where $F(x) = \bigl (f_1(x)$, 
$f_2(x), f_3(x)\bigr )$ and $J_{k}$ is the cardinality of $X^{(k)}$ (and 
$P^{(k)}$). Note that for the very first iteration ($k=0$) the nondominated 
set $X^{(0)}$ is the result of the preprocessing step. For a typical 
$p$-objective optimization problem the Pareto front is a $p-1$ dimensional 
manifold. Hence to construct a $p-1$ dimensional triangulation from a set of
$p$-dimensional point set,  each point ($f_1$, $f_2$, $\ldots$, $f_p$) is
transformed to its homogeneous coordinate of the form ($f_1/f_p$, $f_2/f_p$,
$\ldots$, ${f_{p-1}}/f_p$, $1$) assuming that the objectives are appropriately
scaled. A Delauanay triangulation, $DT$ is constructed using this $p-1$
dimensional transformed data set. The gap between the nondominated points in
the objective space $P^{(k)}$ is computed for each point $F(x^{(k,j)})$, $j=1$,
$\ldots$, $J$, in $P^{(k)}$ as follows, 
for $i=1$, $2$, $\ldots$, $n_j$, where $n_j$ is the number of neighbors for 
the point $F(x^{(k,j)})$ in $DT$,
$\delta_j^k={{\sum_{i=1}^{n_j}{\|F(x^{(k,j)})-F(x^{(k,i)})\|_2}}\over {n_j}}$. 
The point $x_c^{(k)}$ with the largest $\delta_j^k$ 
value is selected as the most isolated point, and is used as the center point 
for a local model with a trust region radius $\Delta^k$. Thus,

\noindent if $J_k > 2$, $x_c^{(k)} := x^{(k,i)}$, where $i=$\hbox{argmax}
$[\delta_j^k]$, $j=2$, $\ldots$, $J-1$,

\noindent if $J_k = 2$,  $x_c^{(k)} := x^{(k,1)}$ or $x^{(k,2)}$ (select 
randomly),

\noindent if $J_k = 1$, $x_c^{(k)} := x^{(k,1)}$.

At the end of each iteration the point $x_c^{(k)}$ and the trust region radius 
$\Delta^k$ for the iteration $k$ are stored in a database. If $x_c^{(k)}$ 
happens to be a previously visited point (for $k > 0$) i.e., if $\exists 
i\in\{1$, $2$, $\ldots$, $k-1\}$, such that $x_c^{(k)} = x_c^{(i)}$, the trust 
region radius is modified as $\Delta^k := \rho\Delta^i$, and if the new 
$\Delta^k$ value is greater than $\tau$, $x_c^{(k)}$ is the center point for 
the local model for the next iteration; otherwise $x_c^{(k)}$ is accepted as a 
Pareto optimal point (and excluded from further consideration as an isolated 
point) and the above procedure is repeated until a new isolated point is 
found. When a previously visited point $x_c^i$ is encountered it indicates 
that the algorithm failed to produce any better points (i.e., a point that
dominates the center point) at the $i^{th}$ iteration. This behaviour could 
be explained in either of the two situations: the surrogate for the local 
trust region for the ${i^{th}}$ iteration was not accurate enough or $x_c^i$ is 
a locally Pareto optimal point. Reducing the trust region radius (and generating 
a new experimental design) would help in constructing a more accurate surrogate 
to check if any better points around $x_c^i$ exist. \smallskip

In classic trust region algorithms a trust region is expanded when the surrogate 
is in a reasonablly good agreement with the true objective function. In the 
proposed algorithm the center point and hence, the trust region at each 
iteration changes as a result of the process of identifying the most isolated 
point, and weights are redetermined at each iteration that changes the resulting 
objective function. As a result, the nature of the objective function changes 
at each iteration, and hence it cannot be guaranteed that a good surrogate for 
one iteration is good for the next iteration as well. Hence the expansion 
of the trust region is omitted in the proposed algorithm. \smallskip

\noindent{\bf Step 2: Surrogates}\smallskip

\noindent The algorithm uses a linear Shepard method (LSHEP from 
\TZWBIB) to approximate a response surface within a trust region. The 
isolated point $x_c^{(k)}$ determined in the previous step serves as the center 
point for the local trust region with radius $\Delta^k$ taken as the 
intersection of the local trust region box $\bigl\{x\mid\|x-x_c^{(k)}\|_\infty 
\le\Delta^k \bigr\}$ with the box $[l,u]$ defined by the variable bounds $l\le 
x \le u$. A tuning parameter $\epsilon$ for DIRECT allows a user to control 
the exploration mode for DIRECT (local versus global). The number of points to 
be sampled can be specified as an input to DIRECT, as for a Latin hypercube, 
the difference being deterministic adaptive rather than random point placement. 
The points to be sampled using DIRECT are based on the value of the 
aggregate objective constructed as a convex combination of the $p$ objective 
functions. At the end of a single run of DIRECT, a data set $D^{(k)}={\Bigl\{
\bigl (x, f_1(x), f_2(x), \ldots, f_p(x)\bigr)\mid x\in X_d^{(k)} \Bigr\}}$ 
of design samples $x\in X_d^{(k)}$ and system analyses $f_1$, $f_2$
$\ldots$, $f_p(x)$ is generated. $p$ LSHEP \TZWBIB\ surrogates $\tilde f_1$,
$\tilde f_2$, $\ldots$, $\tilde f_p$ are built for the $p$ objective functions
using the database $D^{(k)}$. At every iteration, several single objective
optimization problems are formulated using convex combinations of these
surrogates. $p$ of the weight combinations used have the fixed values for 
each iteration to compute the individual optima of the $p$ surrogates.
Additional weights are derived using an adaptive weighting scheme. Based on the
value of the objective function at the center point $x_c^{(k)}$ for an
iteration and its $n$ neighbors, at most $n$ additional weights are computed at 
every iteration as follows. 
$$\hbox{If } J_k \ge 2, {w_j^i={c^i {1 \over {\bigl (f_j(x_c^{(k)})-f_j(x^{(k,i)})\bigr) }} }},$$ 
$$\hbox{  for } i=1,\ldots,n; j=1,\ldots,p; {(f_j(x_c^{(k)})-f_j(x^{(k,i)})\bigr)}>0,$$

$$\hbox{if } J_k = 1, w= [w_1,w_2,\ldots,w_p] = [1/p,\ldots,1/p]$$

\noindent where $c^i$ is a constant leading to ${\sum_{i=1}^n w_i}=1$. 

\par\noindent Thus, the surrogates constructed at each iteration include 
 $$s_j = \tilde f_j \hbox{ for } j=1, \ldots, p.$$

\par\noindent if $J^k \ge 2$,\quad 
$$s_i =\sum_{j=1}^p w_j^{i}s_j, \hbox{ for } i=1, \ldots, n.$$

\par\noindent if $J^k < 2$,\quad  
$$s = \sum_{j=1}^n w_js_j.$$\smallskip

\noindent{\bf Step 3: Solving optimization problems}\smallskip

\noindent Each of the surrogates constructed in Step 2 is optimized using MADS 
to get a candidate solution. Thus at the end of each iteration at most four 
candidate Pareto solutions are obtained, evaluated to get their true function 
values, and then nondominated solutions among those are selected. Let $X_*^{
(k)}$ be a set of these nondominated solutions. An updated set $X^{(k+1)}$ of 
nondominated points is obtained at the end of iteration $k$ by comparing all 
points from the  union $X^{(k)}\cup X_d^{(k)}\cup X_*^{(k)}$.

These three steps are iterated by the algorithm until a stopping 
condition is satisfied. In practice, termination is either set to a fixed 
number of iterations, or when the value of the star discrepancy (discussed 
in detail in the next section) drops below a predefined threshold.
\vskip -3pt

\section{4}{Numerical Evaluation}\vskip -3pt
\section{4.1}{Performance Measures}
\section{4.2}{Parameter Setup}
\section{4.3}{Test Problems}\vskip -3pt
\section{4.4}{Results and Discussion}\vskip -3pt

\section{5}{Conclusion and Future Work}

\bigskip
\noindent{\bf References}
\newbox\refbox
\setbox\refbox=\hbox{\rmIX [55] }\newcount\refnum \refnum=0
\def\refb#1#2#3{{\noindent\hangindent=\wd\refbox\hangafter=1 % book
\global\advance\refnum by 1
\rmIX\hbox to \wd\refbox{\hss[\number\refnum] }#1,
{\slIX #2}, #3\par}}
\def\refj#1#2#3#4{{\noindent\hangindent=\wd\refbox\hangafter=1 % journal
\global\advance\refnum by 1
\rmIX\hbox to \wd\refbox{\hss[\number\refnum] }#1, ``#2,''
{\slIX #3}, #4\par}}
\def\reftr#1#2#3{{\noindent\hangindent=\wd\refbox\hangafter=1 % tech rep
\global\advance\refnum by 1
\rmIX\hbox to \wd\refbox{\hss[\number\refnum] }#1, ``#2,'' #3\par}}
\def\refp#1#2#3#4{{\noindent\hangindent=\wd\refbox\hangafter=1 % proc
\global\advance\refnum by 1
\rmIX\hbox to \wd\refbox{\hss[\number\refnum] }#1, ``#2,'' in
{\slIX #3}, #4\par}}
\def\lrule{\leaders\hrule\hskip 2em}\frenchspacing
%
% begin references without a blank line.
\smallskip
\refj %AD
{Audet C. and Dennis J. E.}{Mesh adaptive direct search algorithms for 
constrained optimization}{SIAM Journal on Optimization}{Vol 17, No. 1, 
pp. 188-217, 2006}

\refj %ASZ
{Audet C., Savard G., and Zghal W.}{A mesh adaptive direct search algorithm 
for multiobjective optimization}{European Journal of Operational Research}
{Vol. 204, pp. 545-556, 2010}

\refj %ASZI
{Audet C., Savard G., and Zghal W.}{Multiobjective optimization through a 
series of single objective formulations}{SIAM Journal of Optimization}
{Vol. 19, pp. 188-210, 2008}

\refj %C
{Caflisch R. E.}{Monte Carlo and quasi-Monte Carlo methods}{Acta Numerica}{vol. 
7, pp. 1--49, 1998}

\refj %D
{Deb K.}{Multiobjective genetic algorithms: problem difficulties and 
construction of test problems}{Evol. Comput.}{Vol. 7. pp. 205---230, 1999}

\refj %DPAM
{Deb, K., Pratap. A, Agarwal, S., and Meyarivan, T.}{A fast and elitist 
multiobjective genetic algorithm: NSGA-II}{IEEE Transaction on Evolutionary 
Computation}{6(2), pp. 181-197, 2002}

\refb %DT
{Digabel S. L. and Tribes C.}{NOMAD user guide version 3.5.1}{Mar, 2012}

\refp %DWC
{Deshpande S. G., Watson L. T., and Canfield R. A.}{Biobjective Optimization 
using Direct Search Techniques }{IEEE SoutheastCon}{Jacksonville, FL, Apr 4-7, 
2013}

\refb %E
{Eichfelder G.}{Adaptive Scalarization Methods in Multiobjective Optimization 
(Vector Optimization)}{Springer, 2008}

\refj %GF
{Gray G. A. and Fowler K. R. (2011)}{Traditional and hybrid derivative-free 
optimization approaches for black box functions}{Computational Optimization, 
Methods and Algorithms}{356}{125-151}

\refj %HWRSVJBT
{He J., Watson L. T., Ramakrishnan N., Shaffer C. A., Verstak A., Jiang J., 
Bae K., and Tranter W. H.}{Dynamic data structures for a direct search 
algorithm}{Computational Optimization and Applications}{Vol. 23, pp. 5--25, 
2002} 

\refj %JPS
{Jones D. R., Perttunen  C. D., and Stuckman B. E.}{Lipschitzian optimization
without the Lipschitz constant}{Journal of Optimization Theory and Application} 
{Vol. 79, No. 1, pp. 157-181, 1993}

\refp %KWT
{Kugele S. C., Watson L. T., and Trosset M. W.}{Multidimensional numerical 
integration for robust design optimization}{ACM Southeast Regional Conference}
{pp. 385-390, 2007}

\refj %MM
{Jones D. R., Perttunen  C. D., and Stuckman B. E.}{Lipschitzian optimization
without the Lipschitz constant}{Journal of Optimization Theory and Application} 
{Vol. 79, No. 1, pp. 157-181, 1993}

\refp %RKW
{Ryu J., Kim S., and Wan H.}{Pareto front approximation with adaptive weighted 
sum method in multiobjective simulation optimization}{Proceedings of the 2009
Winter Simulation Conference}{pp. 623-633, Austin, TX, USA, 2009}

\refj %TZWBIB
{Thacker W. I., Zhang J, Watson L. T., Birch J. B., Iyer M. A., Barry M. W.}
{Algorithm 905: SHEPPACK: modified Shepard algorithm for interpolation of 
scattered multivariate data}{ACM Trans. Math. Software}{vol. 37, pp. 1-20, 
2010}

\refb %VL
{Veldhuizen D. A. and Lamont G. B}{Evolutionary Computation and 
Convergence to a Pareto Front}{Stanford University Bookstore, 1998}

\refp %WIHM
{Wang L., Ishida H., Hiroyashu T., and Miki M.}{Examination of 
multiobjective optimization method for global search using DIRECT and GA}
{IEEE World Congress on Computational Intelligence}{pp 2446--2451, 2008}

\bye
